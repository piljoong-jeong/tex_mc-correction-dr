% \documentclass[acmtog,anonymous,review]{acmart}
% \acmSubmissionID{1234}
\documentclass[acmtog,review]{acmart}

\usepackage{booktabs} % For formal tables
\usepackage{xcolor}
\definecolor{steelblue}{rgb}{0.27, 0.51, 0.71}
\newcommand{\PJ}[1]{\textcolor{steelblue}{\bfseries{PJ: {#1}}}}
\usepackage{amsmath}
% \usepackage{amssymb} % symbol already defined
% \usepackage{newtxmath}
% \usepackage{preamble-math}

% \usepackage{newunicodechar}
% \newunicodechar{âŠ•}{reg_op}

\usepackage[T1]{fontenc}
\usepackage{fixltx2e}

% TOG prefers author-name bib system with square brackets
\citestyle{acmauthoryear}
%\setcitestyle{nosort,square} % nosort to allow for manual chronological ordering



\usepackage[ruled]{algorithm2e} % For algorithms
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}

% Metadata Information
\acmJournal{TOG}
%\acmVolume{38}
%\acmNumber{4}
%\acmArticle{39}
%\acmYear{2019}
%\acmMonth{7}

% Copyright
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% DOI
%\acmDOI{0000001.0000001_2}

% Paper history
%\received{February 2007}
%\received{March 2009}
%\received[final version]{June 2009}
%\received[accepted]{July 2009}



% Document starts
\begin{document}

% Title portion
\title{Single-view TSDF Mesh Noise Reduction under Virtual Light using Differentiable Rendering}

% DO NOT ENTER AUTHOR INFORMATION FOR ANONYMOUS TECHNICAL PAPER SUBMISSIONS TO SIGGRAPH 2019!
\author{PilJoong Jeong}
\orcid{0000-0001-7579-2047}
\affiliation{
 \institution{Gwangju Institute of Science and Technology}
 \streetaddress{123 Cheomdangwagi-ro}
 \city{Buk-gu}
 \state{Gwangju}
 \postcode{61005}
 \country{Republic of Korea}}
\email{piljoong.jeong@gm.gist.ac.kr}

%\renewcommand\shortauthors{Jeong, P. et al}

\begin{teaserfigure}
    \includegraphics[width=\textwidth]{figures/0_teaser_overview_rev3.png}
    \caption{Overview of our method. (From top left) We saturate noisy vertices by rendering input TSDF mesh with virtually placed light source. We extract common-shared geometric clue between rendered input mesh and target color image. Differentiable renderer iteratively minimizes loss, which is the difference between clues from rendered input mesh and target Ground Truth color image. Orange, Yellow, and Blue inset shows difference between input mesh and optimized mesh. Our method successfully reduces noise in mesh vertices. Furthermore, our provided video shows input mesh that is being optimized (right-side of the video) as iteration continues, as well as the visualization of loss (left-side of the video) that is being minimized: \url{https://drive.google.com/file/d/10F_I89m5O-RWOIxocYoxG2QOkJc7YWlF/view?usp=sharing}}
    \label{fig:one}
\end{teaserfigure}

\begin{abstract}
Thanks to consistent evolution of SLAM (Simultaneous Localization and Mapping) and its related technologies, we can reconstruct geometric properties of where we are currently observing in real-time. Due to the limitation of current depth sensing hardware, however, we are generally able to obtain geometric features corrupted by noise. Color image is perceived as geometrically noise-free in terms of human vision-perception system, but to our best knowledge, encoding the information from Ground Truth for differentiable rendering under single view constraint is not discussed yet. In this report, we propose a bridge between the geometric information generated from color image and rendered mesh, so that differentiable renderer can optimize input i.e., noisy vertex position without any depth supervision. The key insight is that we can highlight noisy vertices by rendering mesh with virtually placed light sources. We compare our result with one of the state-of-the-art differentiable rendering method[1], and show our method outperforms previous method which requires prior depth information (silhouette image).
\end{abstract}


%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below.
%
\begin{CCSXML}
<ccs2012>
    <concept>
        <concept_id>10010147.10010371.10010396</concept_id>
        <concept_desc>Computing methodologies~Shape modeling</concept_desc>
        <concept_significance>500</concept_significance>
        </concept>
    <concept>
        <concept_id>10010147.10010371.10010387.10010392</concept_id>
        <concept_desc>Computing methodologies~Mixed / augmented reality</concept_desc>
        <concept_significance>500</concept_significance>
        </concept>
    </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Shape modeling}
\ccsdesc[500]{Computing methodologies~Mixed / augmented reality}

%
% End generated code
%


\keywords{Differentiable rendering, Mesh denoising}



\maketitle

% \input{samplebody-journals}
\input{sections/1_introduction.tex}
\input{sections/2_previous_works.tex}
\input{sections/3_methods.tex}
\input{sections/4_results.tex}
\input{sections/5_conclusions.tex}


\end{document}
